#!/bin/bash
# NASA Space Biology Knowledge Engine - Complete Installation Script
# This script installs all dependencies and sets up the environment

echo "ğŸš€ NASA Space Biology Knowledge Engine Installation"
echo "=================================================="

# Check Python version
python_version=$(python --version 2>&1)
echo "ğŸ“‹ Detected Python version: $python_version"

# Upgrade pip
echo "ğŸ“¦ Upgrading pip..."
python -m pip install --upgrade pip

# Install requirements
echo "ğŸ“¦ Installing Python packages from requirements.txt..."
pip install -r requirements.txt

# Download spaCy language model (CRITICAL)
echo "ğŸ“¥ Downloading spaCy language model..."
python -m spacy download en_core_web_sm

# Download NLTK data
echo "ğŸ“¥ Downloading NLTK data..."
python -c "
import nltk
try:
    nltk.data.find('tokenizers/punkt')
    print('âœ… NLTK punkt tokenizer already available')
except LookupError:
    print('ğŸ“¥ Downloading NLTK punkt tokenizer...')
    nltk.download('punkt')
    print('âœ… NLTK punkt tokenizer downloaded')
"

# Verify spaCy installation
echo "ğŸ” Verifying spaCy installation..."
python -c "
import spacy
try:
    nlp = spacy.load('en_core_web_sm')
    print('âœ… spaCy model loaded successfully')
    print(f'   Model info: {nlp.meta[\"name\"]} v{nlp.meta[\"version\"]}')
except OSError:
    print('âŒ spaCy model failed to load')
    print('   Run: python -m spacy download en_core_web_sm')
    exit(1)
"

# Verify core imports
echo "ğŸ” Verifying core package imports..."
python -c "
import sys

packages_to_test = [
    'streamlit', 'pandas', 'requests', 'beautifulsoup4', 'nltk', 
    'spacy', 'networkx', 'plotly', 'torch', 'transformers', 
    'numpy', 'scipy', 'sklearn', 'psutil', 'pytest'
]

failed_imports = []
for package in packages_to_test:
    try:
        if package == 'beautifulsoup4':
            import bs4
        elif package == 'sklearn':
            import sklearn
        else:
            __import__(package)
        print(f'âœ… {package}')
    except ImportError as e:
        print(f'âŒ {package}: {e}')
        failed_imports.append(package)

if failed_imports:
    print(f'\\nâš ï¸ Failed to import: {failed_imports}')
    print('Please install missing packages manually.')
    sys.exit(1)
else:
    print('\\nğŸ‰ All required packages imported successfully!')
"

# Test transformers availability
echo "ğŸ¤– Testing AI model availability..."
python -c "
try:
    from transformers import pipeline
    # Test with a small model for quick verification
    classifier = pipeline('sentiment-analysis', 
                         model='distilbert-base-uncased-finetuned-sst-2-english',
                         return_all_scores=False)
    result = classifier('This is a test.')
    print('âœ… Transformers pipeline working')
    print(f'   Test result: {result}')
except Exception as e:
    print(f'âš ï¸ Transformers test failed: {e}')
    print('   AI summarization may use fallback methods')
"

# Create data directories
echo "ğŸ“ Creating data directories..."
mkdir -p data
mkdir -p logs
mkdir -p cache
echo "âœ… Directories created: data/, logs/, cache/"

# Check available models
echo "ğŸ“‹ Checking available AI models..."
python -c "
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import torch

models_to_check = [
    'facebook/bart-large-cnn',
    'facebook/bart-base', 
    'sshleifer/distilbart-cnn-12-6',
    't5-small'
]

print('Available models:')
for model_name in models_to_check:
    try:
        # Just check if model config is accessible
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        print(f'âœ… {model_name}')
    except Exception as e:
        print(f'âš ï¸ {model_name}: May need download on first use')

print(f'\\nPyTorch CUDA available: {torch.cuda.is_available()}')
print(f'PyTorch device: {\"cuda\" if torch.cuda.is_available() else \"cpu\"}')
"

echo ""
echo "ğŸ‰ Installation Complete!"
echo "======================="
echo ""
echo "ğŸš€ To run the application:"
echo "   streamlit run app.py"
echo ""
echo "ğŸ§ª To run tests:"
echo "   pytest tests/ -v"
echo ""
echo "ğŸ“– To validate the complete pipeline:"
echo "   python test_final_integration.py"
echo ""
echo "ğŸ’¡ First run may be slow as AI models download automatically"
echo ""